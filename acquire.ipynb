{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a780d6d",
   "metadata": {},
   "source": [
    "# Acquire Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb81672",
   "metadata": {},
   "source": [
    "The end result of this exercise should be a file named acquire.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765a50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c8d8d3",
   "metadata": {},
   "source": [
    "## 1. Using the code from the lesson as a guide and the REST API from https://python.zgulde.net/api/v1/items as we did in the lesson, create a dataframe named `items` that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877ee1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://python.zgulde.net'\n",
    "endpoint = '/api/v1/items'\n",
    "items = []\n",
    "\n",
    "url = domain + endpoint\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "# .extend adds elemnts from a list to another list\n",
    "items.extend(data['payload']['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd36ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/api/v1/items?page=2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['payload']['next_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd17fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next url: https://python.zgulde.net/api/v1/items?page=2\n"
     ]
    }
   ],
   "source": [
    "url = domain + data['payload']['next_page']\n",
    "print('Next url:', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4187a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "items.extend(data['payload']['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a6d809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next url: https://python.zgulde.net/api/v1/items?page=3\n"
     ]
    }
   ],
   "source": [
    "url = domain + data['payload']['next_page']\n",
    "print('next url:', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b41c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "items.extend(data['payload']['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee6c077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next endpoint None\n"
     ]
    }
   ],
   "source": [
    "# Hint hint: if data['payload']['next_page'] is None:\n",
    "print('next endpoint', data['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "92497fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsdf = pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c6834",
   "metadata": {},
   "source": [
    "## 2. Do the same thing, but for stores (https://python.zgulde.net/api/v1/stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c3af440",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://python.zgulde.net'\n",
    "endpoint = '/api/v1/stores'\n",
    "stores = []\n",
    "\n",
    "url = domain + endpoint\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "# .extend adds elemnts from a list to another list\n",
    "stores.extend(data['payload']['stores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39da6913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next endpoint None\n"
     ]
    }
   ],
   "source": [
    "print('next endpoint', data['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f288d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "storesdf = pd.DataFrame(stores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ba436",
   "metadata": {},
   "source": [
    "## 3. Extract the data for sales (https://python.zgulde.net/api/v1/sales). There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70555529",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://python.zgulde.net'\n",
    "endpoint = '/api/v1/sales'\n",
    "sales = []\n",
    "url = domain + endpoint\n",
    "\n",
    "page = 1\n",
    "while page < data['payload']['max_page']:\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    # .extend adds elemnts from a list to another list\n",
    "    sales.extend(data['payload']['sales'])\n",
    "    # Set the url for the page\n",
    "    url = domain + data['payload']['next_page']\n",
    "\n",
    "    page +=1\n",
    "\n",
    "# url = domain + data['payload']['next_page']\n",
    "# response = requests.get(url)\n",
    "# data = response.json()\n",
    "# sales.extend(data['payload']['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "09255c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = domain + data['payload']['next_page']\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "sales.extend(data['payload']['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7a04cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdf = pd.DataFrame(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b12649ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913000, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9f378ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              1\n",
       "1              2\n",
       "2              3\n",
       "3              4\n",
       "4              5\n",
       "           ...  \n",
       "912995    912996\n",
       "912996    912997\n",
       "912997    912998\n",
       "912998    912999\n",
       "912999    913000\n",
       "Name: sale_id, Length: 913000, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.sale_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86524eac",
   "metadata": {},
   "source": [
    "## 4. Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "faba2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsdf.to_csv('items.csv', index =False)\n",
    "storesdf.to_csv('stores.csv', index =False)\n",
    "salesdf.to_csv('sales.csv', index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7483c80",
   "metadata": {},
   "source": [
    "## 5. Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "895a09e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item', 'sale_amount', 'sale_date', 'sale_id', 'store'], dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6b370df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_brand', 'item_id', 'item_name', 'item_price', 'item_upc12',\n",
       "       'item_upc14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemsdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "975e2ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store_address', 'store_city', 'store_id', 'store_state',\n",
       "       'store_zipcode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storesdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b4fd2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdf = salesdf.rename(columns = {'item': 'item_id', 'store':'store_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "61e1aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(salesdf, itemsdf, how='left', on='item_id')\n",
    "df = pd.merge(df, storesdf, how='left', on='store_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5f51a0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913000, 14)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1392c3d",
   "metadata": {},
   "source": [
    "## 6. Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here:\n",
    "https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e04d390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8bf08605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Consumption</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Solar</th>\n",
       "      <th>Wind+Solar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>1069.184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-02</td>\n",
       "      <td>1380.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>1442.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>1457.217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>1477.131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Consumption  Wind  Solar  Wind+Solar\n",
       "0  2006-01-01     1069.184   NaN    NaN         NaN\n",
       "1  2006-01-02     1380.521   NaN    NaN         NaN\n",
       "2  2006-01-03     1442.533   NaN    NaN         NaN\n",
       "3  2006-01-04     1457.217   NaN    NaN         NaN\n",
       "4  2006-01-05     1477.131   NaN    NaN         NaN"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ef2729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opsd():\n",
    "    if os.path.exists('opsd.csv'):\n",
    "        return pd.read_csv('opsd.csv')\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')\n",
    "    df.to_csv('opsd.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f759fa",
   "metadata": {},
   "source": [
    "## 7. Make sure all the work that you have done above is reproducible. That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
