{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting \n",
    "\n",
    "\n",
    "In this lesson, we will practice forecasting using the following methods:  \n",
    "\n",
    "- Last observed value  \n",
    "- Simple average  \n",
    "- Moving average  \n",
    "- Holt's Linear Trend  \n",
    "- Previous cycle  \n",
    "\n",
    "______________________________\n",
    "\n",
    "\n",
    "We will walk through steps from previous lessons to get the data ready to model\n",
    "\n",
    "- Acquire data: acquire.get_store_item_demand_data()\n",
    "- Prepare data: prepare.prep_store_data()\n",
    "\n",
    "Then we will forecast and evaluate using each method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for presentation purposes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualize \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# wrangle\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "# working with dates\n",
    "from datetime import datetime\n",
    "\n",
    "# to evaluated performance using rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt \n",
    "\n",
    "# for tsa \n",
    "import statsmodels.api as sm\n",
    "\n",
    "# holt's linear trend model. \n",
    "from statsmodels.tsa.api import Holt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_whole_sales()\n",
    "df = prepare.prep_sales(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will resample to daily, but essentially what we are doing is grouping by the day and aggregating using sum. The original granularity is daily, but there are multiple records of the same days across multiple stores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sale_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_brand</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_upc12</th>\n",
       "      <th>item_upc14</th>\n",
       "      <th>store_address</th>\n",
       "      <th>store_city</th>\n",
       "      <th>store_state</th>\n",
       "      <th>store_zipcode</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sales_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>12</td>\n",
       "      <td>26.0</td>\n",
       "      <td>211817</td>\n",
       "      <td>7</td>\n",
       "      <td>Mueller</td>\n",
       "      <td>Mueller Sport Care Basic Support Level Medium Elastic Knee Support</td>\n",
       "      <td>8.40</td>\n",
       "      <td>74676640211</td>\n",
       "      <td>74676640211</td>\n",
       "      <td>12018 Perrin Beitel Rd</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>78217</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>218.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>46</td>\n",
       "      <td>27.0</td>\n",
       "      <td>832657</td>\n",
       "      <td>7</td>\n",
       "      <td>Mama Marys</td>\n",
       "      <td>Pizza Sauce</td>\n",
       "      <td>4.65</td>\n",
       "      <td>35457770664</td>\n",
       "      <td>35457770664</td>\n",
       "      <td>12018 Perrin Beitel Rd</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>78217</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>125.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>12</td>\n",
       "      <td>54.0</td>\n",
       "      <td>213643</td>\n",
       "      <td>8</td>\n",
       "      <td>Mueller</td>\n",
       "      <td>Mueller Sport Care Basic Support Level Medium Elastic Knee Support</td>\n",
       "      <td>8.40</td>\n",
       "      <td>74676640211</td>\n",
       "      <td>74676640211</td>\n",
       "      <td>15000 San Pedro Ave</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>78232</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>453.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>12</td>\n",
       "      <td>35.0</td>\n",
       "      <td>215469</td>\n",
       "      <td>9</td>\n",
       "      <td>Mueller</td>\n",
       "      <td>Mueller Sport Care Basic Support Level Medium Elastic Knee Support</td>\n",
       "      <td>8.40</td>\n",
       "      <td>74676640211</td>\n",
       "      <td>74676640211</td>\n",
       "      <td>735 SW Military Dr</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>78221</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>294.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            item_id  sale_amount  sale_id  store_id  item_brand  \\\n",
       "sale_date                                                         \n",
       "2013-01-01        1         13.0        1         1    Riceland   \n",
       "2013-01-01       12         26.0   211817         7     Mueller   \n",
       "2013-01-01       46         27.0   832657         7  Mama Marys   \n",
       "2013-01-01       12         54.0   213643         8     Mueller   \n",
       "2013-01-01       12         35.0   215469         9     Mueller   \n",
       "\n",
       "                                                                     item_name  \\\n",
       "sale_date                                                                        \n",
       "2013-01-01                                      Riceland American Jazmine Rice   \n",
       "2013-01-01  Mueller Sport Care Basic Support Level Medium Elastic Knee Support   \n",
       "2013-01-01                                                         Pizza Sauce   \n",
       "2013-01-01  Mueller Sport Care Basic Support Level Medium Elastic Knee Support   \n",
       "2013-01-01  Mueller Sport Care Basic Support Level Medium Elastic Knee Support   \n",
       "\n",
       "            item_price   item_upc12   item_upc14           store_address  \\\n",
       "sale_date                                                                  \n",
       "2013-01-01        0.84  35200264013  35200264013  12125 Alamo Ranch Pkwy   \n",
       "2013-01-01        8.40  74676640211  74676640211  12018 Perrin Beitel Rd   \n",
       "2013-01-01        4.65  35457770664  35457770664  12018 Perrin Beitel Rd   \n",
       "2013-01-01        8.40  74676640211  74676640211     15000 San Pedro Ave   \n",
       "2013-01-01        8.40  74676640211  74676640211      735 SW Military Dr   \n",
       "\n",
       "             store_city store_state  store_zipcode month day_of_week  \\\n",
       "sale_date                                                              \n",
       "2013-01-01  San Antonio          TX          78253   Jan     Tuesday   \n",
       "2013-01-01  San Antonio          TX          78217   Jan     Tuesday   \n",
       "2013-01-01  San Antonio          TX          78217   Jan     Tuesday   \n",
       "2013-01-01  San Antonio          TX          78232   Jan     Tuesday   \n",
       "2013-01-01  San Antonio          TX          78221   Jan     Tuesday   \n",
       "\n",
       "            sales_total  \n",
       "sale_date                \n",
       "2013-01-01        10.92  \n",
       "2013-01-01       218.40  \n",
       "2013-01-01       125.55  \n",
       "2013-01-01       453.60  \n",
       "2013-01-01       294.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>13696.0</td>\n",
       "      <td>73844.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>13678.0</td>\n",
       "      <td>73570.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>14488.0</td>\n",
       "      <td>78169.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>15677.0</td>\n",
       "      <td>84467.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>16237.0</td>\n",
       "      <td>87621.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sale_amount  sales_total\n",
       "sale_date                           \n",
       "2013-01-01      13696.0     73844.01\n",
       "2013-01-02      13678.0     73570.58\n",
       "2013-01-03      14488.0     78169.48\n",
       "2013-01-04      15677.0     84467.73\n",
       "2013-01-05      16237.0     87621.85"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled = df.resample('d')[['sale_amount','sales_total']].sum()\n",
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "1. We will use the training proportion method to split.    \n",
    "2. Identify the total length of the dataframe and multiply by `train_prop` to get the number of rows that equates to the first x% of the dataframe, which equates to the first x% of the time covered in the data.   (`x = train_prop * 100`)  \n",
    "3. Select row indices from 0 up to the index representing x-percentile for train, and from the index representing x-percentile through the end of the dataframe for test. In both of these, we will reset the index in order to return dataframes sorted by datetime.  \n",
    "4. Return train and test dataframes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set train size to be 50% of total \n",
    "train_size = int(round(df_resampled.shape[0] * 0.5))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set validate size to be 30% of total \n",
    "validate_size = int(round(df_resampled.shape[0] * 0.3))\n",
    "validate_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set test size to be number of rows remaining. \n",
    "test_size = int(round(df_resampled.shape[0] * 0.2))\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_resampled) == train_size + validate_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate will go from 913 to 913+548\n",
    "validate_end_index = train_size + validate_size\n",
    "validate_end_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use those values to split our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train will go from 0 to 912\n",
    "train = df_resampled[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate will go from 912 to 1458\n",
    "validate = df_resampled[train_size:validate_end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test will include 1459 to the end\n",
    "test = df_resampled[validate_end_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0], validate.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify Splits**\n",
    "\n",
    "Does the length of each df equate to the length of the original df? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is len of train + validate + test == lenght of entire dataframe. \n",
    "len(train) + len(validate) + len(test) == len(df_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the first row of original df equate to the first row of train? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_resampled.head(1) == train.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the last row of train the day before the first row of validate? And the same for validate to test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train.tail(1), validate.head(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([validate.tail(1), test.head(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the last row of test the same as the last row of our original dataframe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([test.tail(1), df_resampled.tail(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our data first, viewing where the data is split into train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.plot(train[col])\n",
    "    plt.plot(validate[col])\n",
    "    plt.plot(test[col])\n",
    "    plt.ylabel(col)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try out different methods for forecasting sales and number of items sold, let's create a couple of functions that will be helpful in evaluating each of the methods that follow. \n",
    "\n",
    "`evaluate()` will compute the Mean Squared Error and the Rood Mean Squared Error to evaluate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_var):\n",
    "    '''\n",
    "    This function will take the actual values of the target_var from validate, \n",
    "    and the predicted values stored in yhat_df, \n",
    "    and compute the rmse, rounding to 0 decimal places. \n",
    "    it will return the rmse. \n",
    "    '''\n",
    "    rmse = round(sqrt(mean_squared_error(validate[target_var], yhat_df[target_var])), 0)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_and_eval()` will use the evaluate function and also plot train and test values with the predicted values in order to compare performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_eval(target_var):\n",
    "    '''\n",
    "    This function takes in the target var name (string), and returns a plot\n",
    "    of the values of train for that variable, validate, and the predicted values from yhat_df. \n",
    "    it will als lable the rmse. \n",
    "    '''\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(train[target_var], label='Train', linewidth=1)\n",
    "    plt.plot(validate[target_var], label='Validate', linewidth=1)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var)\n",
    "    print(target_var, '-- RMSE: {:.0f}'.format(rmse))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write `append_eval_df(model_type)` to append evaluation metrics for each model type, target variable, and metric type, along with the metric value into our `eval_df` data frame object. Which we will create an empty `eval_df` dataframe object to start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "eval_df = pd.DataFrame(columns=['model_type', 'target_var', 'rmse'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to store the rmse so that we can compare\n",
    "def append_eval_df(model_type, target_var):\n",
    "    '''\n",
    "    this function takes in as arguments the type of model run, and the name of the target variable. \n",
    "    It returns the eval_df with the rmse appended to it for that model and target_var. \n",
    "    '''\n",
    "    rmse = evaluate(target_var)\n",
    "    d = {'model_type': [model_type], 'target_var': [target_var],\n",
    "        'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast \n",
    "\n",
    "Forecasting is another word for predicting time series data. \n",
    "\n",
    "1. Last Observed Value: The future will look like the now\n",
    "2. Simple Average: The future will look, on average, like history. \n",
    "3. Moving Average: The future will look, on average, like recent history. \n",
    "4. Holt's Linear Trend\n",
    "5. Previous Cycle\n",
    "\n",
    "\n",
    "### Last observed value\n",
    "\n",
    "The simplest method for forecasting is to predict all future values to be the last observed value.  \n",
    "\n",
    "**Make Predictions**\n",
    "\n",
    "Sales Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sales_total'][-1:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the last item of sales total and assign to variable\n",
    "last_sales = train['sales_total'][-1:][0]\n",
    "last_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the last item of quantity and assign to variable\n",
    "last_quantity = train['quantity'][-1:][0]\n",
    "last_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = pd.DataFrame(\n",
    "    {'sales_total': [last_sales],\n",
    "     'quantity': [last_quantity]},\n",
    "    index=validate.index)\n",
    "\n",
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, when peeking into yhat_df, that every predicted value is the same.  \n",
    "\n",
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_eval('sales_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate** \n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'last_observed_value', \n",
    "                             target_var = col)\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Average\n",
    "\n",
    "Take the simple average of historical values and use that value to predict future values.   \n",
    "\n",
    "This is a good option for an initial baseline. Every future datapoint (those in 'test') will be assigned the same value, and that value will be the overall mean of the values in train. \n",
    "\n",
    "**Make Predictions**\n",
    "\n",
    "Dollars: establishing the value of the prediction we will make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute simple average\n",
    "avg_sales = round(train['sales_total'].mean(), 2)\n",
    "avg_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items: establishing the value of the prediction we will make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_quantity = round(train['quantity'].mean(), 2)\n",
    "avg_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply predictions to our observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(sales=None, quantity=None):\n",
    "    yhat_df = pd.DataFrame({'sales_total': [sales],\n",
    "                           'quantity': [quantity]},\n",
    "                          index=validate.index)\n",
    "    return yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = make_predictions(avg_sales, avg_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot and evaluate the performance of our time series model using **Simple Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**\n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type='simple_average', \n",
    "                            target_var = col)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average\n",
    "\n",
    "In this example, we will use a 30-day moving average to forecast. In other words, the average over the last 30-days will be used as the forecasted value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate that the mean of the first 30 days \n",
    "# is equal to rolling(30) on day 30\n",
    "\n",
    "print(train['sales_total'].rolling(30).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period=30\n",
    "train['sales_total'].rolling(period).mean()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 30 \n",
    "\n",
    "# take 30 day rolling average, then take the last element and that will the one that propogates \n",
    "# forward as our prediction. \n",
    "rolling_sales = round(train['sales_total'].rolling(period).mean()[-1], 2)\n",
    "rolling_quantity = round(train['quantity'].rolling(period).mean()[-1], 2)\n",
    "print(rolling_sales, rolling_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = make_predictions(rolling_sales, rolling_quantity)\n",
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot and evaluate the performance of our time series model using **Moving Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**\n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = '30d_moving_avg', \n",
    "                            target_var = col)\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out several other values for periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [4, 12, 26, 52, 104]\n",
    "\n",
    "for p in periods: \n",
    "    rolling_sales = round(train['sales_total'].rolling(p).mean()[-1], 2)\n",
    "    rolling_quantity = round(train['quantity'].rolling(p).mean()[-1], 2)\n",
    "    yhat_df = make_predictions(rolling_sales, rolling_quantity)\n",
    "    model_type = str(p) + '_day_moving_avg'\n",
    "    for col in train.columns:\n",
    "        eval_df = append_eval_df(model_type = model_type,\n",
    "                                target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is best so far? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_items_rmse = eval_df[eval_df.target_var == 'quantity']['rmse'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_items_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[eval_df.rmse == min_items_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dollars_rmse = eval_df[eval_df.target_var == 'sales_total']['rmse'].min()\n",
    "\n",
    "eval_df[eval_df.rmse == min_dollars_rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt's Linear Trend\n",
    "\n",
    "\n",
    "Exponential smoothing applied to both the average and the trend (slope).  \n",
    "\n",
    "- $\\alpha$ / smoothing_level: smoothing parameter for mean. Values closer to 1 will have less of a smoothing effect and will give greater weight to recent values.   \n",
    "- $\\beta$ / smoothing_slope: smoothing parameter for the slope. Values closer to 1 will give greater weight to recent slope/values. \n",
    "\n",
    "\n",
    "\n",
    "**Seasonal Decomposition**\n",
    "\n",
    "\n",
    "First, let's take a look at the seasonal decomposition for each target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col, '\\n')\n",
    "sm.tsa.seasonal_decompose(train[col].resample('W').mean()).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    print(col,'\\n')\n",
    "    sm.tsa.seasonal_decompose(train[col].resample('W').mean()).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Holt's Linear Trend\n",
    "\n",
    "**Make Predictions**\n",
    "\n",
    "Now, like we would when using sklearn, we will create the Holt object, fit the model, and make predictions. \n",
    "\n",
    "Holt: \n",
    "\n",
    "- exponential = True/False (exponential vs. linear growth, additive vs. multiplicative)\n",
    "- damped $\\phi$ = True/False: with Holt, forecasts will increase or decrease indefinitely into the future.  To avoid this, use the Damped trend method which has a damping parameter 0< Ï• <1. \n",
    "\n",
    "\n",
    "fit: \n",
    "\n",
    "- smoothing_level ($\\alpha$): value between (0,1)\n",
    "- smoothing_slope ($\\beta$): value between (0,1)\n",
    "- optimized: use the auto-optimization that allow statsmodels to automatically find an optimized value for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_total' \n",
    "# create our Holt's Object\n",
    "model = Holt(train[col], exponential=False, damped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the holt's object\n",
    "model = model.fit(optimized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_items = model.predict(start = validate.index[0],\n",
    "                              end = validate.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing this in a loop for each column\n",
    "for col in train.columns:\n",
    "    model = Holt(train[col], exponential=False, damped=True)\n",
    "    model = model.fit(optimized=True)\n",
    "    yhat_items = model.predict(start = validate.index[0],\n",
    "                              end = validate.index[-1])\n",
    "    yhat_df[col] = round(yhat_items, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To practice the code before putting in a loop, as above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_total'\n",
    "# create the Holt object \n",
    "model = Holt(train[col], exponential=False, damped=True)\n",
    "# fit the model \n",
    "model = model.fit(optimized=True)\n",
    "# make predictions for each date in validate \n",
    "yhat_items = model.predict(start = validate.index[0],\n",
    "                           end = validate.index[-1])\n",
    "# add predictions to yhat_df\n",
    "yhat_df[col] = round(yhat_items, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(target_var = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'holts_optimized', \n",
    "                            target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Based on Previous Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all the 2016 data points, compute the daily delta, year-over-year, average that delta over all the days, and adding that average to the previous year's value on a day will give you the forecast for that day. \n",
    "\n",
    "If a primary cycle is weekly, then you may want to do this on a week-over-week cadence. \n",
    "\n",
    "In the below example:  \n",
    "1. Compute the 365 average year over year differences from 2013 through 2015\n",
    "2. Add that average delta to the values during 2015. \n",
    "3. Set the index in your yhat dataframe to represent the dates those predictions are make for. \n",
    "\n",
    "Let's get started....\n",
    "\n",
    "**Re-split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_resampled[:'2015']\n",
    "validate = df_resampled['2016']\n",
    "test = df_resampled['2017']\n",
    "\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train.head()\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the year-over-year difference for each day from 2013 to 2015\n",
    "# taking the mean, and then adding that value to the daily 2015 values. \n",
    "\n",
    "# find yoy diff. from 2013-2014 and 2014-2015, take the mean, and add to each value in 2015. \n",
    "yhat_df = train['2015'] + train.diff(365).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.diff(365).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc['2015'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's peek into the prediction we will make for 1/1/2016\n",
    "# by comparing the predicted value \n",
    "# (2015 value + year-over-year average difference)\n",
    "# to the actual 1/1/2016 value\n",
    "pd.concat([yhat_df.head(1), validate.head(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set yhat_df to index of validate\n",
    "yhat_df.index = validate.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape # A leap year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = validate[validate.index != '2016-02-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set yhat_df to index of validate\n",
    "yhat_df.index = validate.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(target_var = col)\n",
    "    eval_df = append_eval_df(model_type = \"previous_year\", \n",
    "                            target_var = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Which model did the best? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_total_min_rmse = eval_df.groupby('target_var')['rmse'].min()[0]\n",
    "\n",
    "quantity_min_rmse = eval_df.groupby('target_var')['rmse'].min()[1]\n",
    "\n",
    "# find which model that is\n",
    "eval_df[((eval_df.rmse == sales_total_min_rmse) | \n",
    "         (eval_df.rmse == quantity_min_rmse))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out on our out-of-sample data\n",
    "\n",
    "We will be using train + validate to predict test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = validate + train.diff(365).mean()\n",
    "yhat_df.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(target_var):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[target_var], label='train')\n",
    "    plt.plot(validate[target_var], label='validate')\n",
    "    plt.plot(test[target_var], label='test')\n",
    "    plt.plot(yhat_df[target_var], alpha=.5)\n",
    "    plt.title(target_var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_sales_total = sqrt(mean_squared_error(test['sales_total'], \n",
    "                                       yhat_df['sales_total']))\n",
    "\n",
    "rmse_quantity = sqrt(mean_squared_error(test['quantity'], \n",
    "                                       yhat_df['quantity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rmse-sales total: ', rmse_sales_total)\n",
    "print('rmse-quantity: ', rmse_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    final_plot(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict 2018\n",
    "\n",
    "yhat_df = test + train.diff(365).mean()\n",
    "\n",
    "yhat_df.index = test.index + pd.Timedelta('1Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(target_var):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[target_var], label='train')\n",
    "    plt.plot(validate[target_var], label='validate')\n",
    "    plt.plot(test[target_var], label='test')\n",
    "    plt.plot(yhat_df[target_var], alpha=.5, label='forecast')\n",
    "    plt.title(target_var)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    final_plot(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "The end result of this exercise should be a Jupyter notebook named `model`.\n",
    "\n",
    "Using [saas.csv](https://ds.codeup.com/saas.csv) or log data from API usage or store_item_sales\n",
    "\n",
    "1. Split data (train/test) and resample by any period, except daily, and aggregate using the sum. \n",
    "2. Forecast, plot and evaluate using each of the 4 parametric based methods we discussed:\n",
    "    - Simple Average\n",
    "    - Moving Average\n",
    "    - Holt's Linear Trend Model\n",
    "    - Based on previous year/month/etc., this is up to you.\n",
    "\n",
    "Optional: Using store item demand\n",
    "\n",
    "1. Predict 2018 total **monthly** sales for a single store and/or item by creating a model using prophet.\n",
    "2. Return a dataframe with the month, store_id, y-hat, and the confidence intervals (y-hat lower, y-hat upper).\n",
    "3. Plot the 2018 monthly sales predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
